{"cells":[{"metadata":{},"cell_type":"markdown","source":["## Leitura do artigo \n","https://www.kaggle.com/wesleyneves/detecting-covid-19-in-x-ray-images-with-tensorflow/edit\n","\n"]},{"metadata":{"trusted":true},"cell_type":"code","source":["!pip install imutils\n","!pip install image-classifiers==1.0.0b1"],"execution_count":1,"outputs":[{"output_type":"stream","text":"Collecting imutils\n  Downloading imutils-0.5.3.tar.gz (17 kB)\nBuilding wheels for collected packages: imutils\n  Building wheel for imutils (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for imutils: filename=imutils-0.5.3-py3-none-any.whl size=25850 sha256=6484f954222060e6f9fc08c562e377305e7ba608dce1f50eb7e02d87f34791df\n  Stored in directory: /root/.cache/pip/wheels/fc/9c/6d/1826267c72afa51b564c9c6e0f66abc806879338bc593a2270\nSuccessfully built imutils\nInstalling collected packages: imutils\nSuccessfully installed imutils-0.5.3\n\u001b[33mWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\nCollecting image-classifiers==1.0.0b1\n  Downloading image_classifiers-1.0.0b1.tar.gz (18 kB)\nBuilding wheels for collected packages: image-classifiers\n  Building wheel for image-classifiers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for image-classifiers: filename=image_classifiers-1.0.0b1-py3-none-any.whl size=19954 sha256=4ffa344671173909b4ac0cf2d2e9c7e0566710bacb9b1bd008c00fe3eeac9015\n  Stored in directory: /root/.cache/pip/wheels/62/1d/1d/d551ddb7ef02acac3373cb39ccd101661f28635a0d91febb69\nSuccessfully built image-classifiers\nInstalling collected packages: image-classifiers\nSuccessfully installed image-classifiers-1.0.0b1\n\u001b[33mWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n","name":"stdout"}]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":["# import the necessary packages\n","import tensorflow as tf\n","import gc\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications import VGG16, DenseNet169\n","from tensorflow.keras.layers import AveragePooling2D\n","from tensorflow.keras.layers import Dropout, GlobalAveragePooling2D, Activation, BatchNormalization, Dropout\n","from tensorflow.keras.layers import Flatten\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Input\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint,TensorBoard,TerminateOnNaN, LearningRateScheduler\n","from tensorflow.keras.losses import binary_crossentropy\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TerminateOnNaN\n","from tensorflow.keras.layers import Lambda, Reshape, DepthwiseConv2D, ZeroPadding2D, Add, MaxPooling2D,Activation, Flatten, Conv2D, Dense, Input, Dropout, Concatenate, GlobalMaxPooling2D, GlobalAveragePooling2D, BatchNormalization\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras import regularizers\n","from tensorflow.keras import backend as K\n","\n","from sklearn.preprocessing import LabelBinarizer\n","from sklearn.model_selection import train_test_split, StratifiedKFold, RepeatedStratifiedKFold\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, auc\n","from imutils import paths\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","import random\n","import shutil\n","import cv2\n","import os\n","# from classification_models.tfkeras import Classifiers\n","from datetime import datetime\n","%load_ext tensorboard"],"execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["dataset_path = r'D:\\Repos\\AprendendoPython\\MachineLearning\\Pos-GraduacaoCovid19\\dataset'\n","log_path = '\\logs'"],"execution_count":9,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## Build Dataset"]},{"metadata":{},"cell_type":"markdown","source":["### Covid xray dataset"]},{"metadata":{"trusted":true},"cell_type":"code","source":["samples = 140"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["covid_dataset_path = r'D:\\Repos\\AprendendoPython\\MachineLearning\\Pos-GraduacaoCovid19\\dataset\\covid'"],"execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# construct the path to the metadata CSV file and load it\n","csvPath = os.path.sep.join([covid_dataset_path, \"metadata.csv\"])\n","df = pd.read_csv(csvPath)\n","\n","# loop over the rows of the COVID-19 data frame\n","for (i, row) in df.iterrows():\n","    # if (1) the current case is not COVID-19 or (2) this is not\n","    # a 'PA' view, then ignore the row\n","    if row[\"finding\"] != \"COVID-19\" or row[\"view\"] != \"PA\":\n","        continue\n","\n","    # build the path to the input image file\n","    imagePath = os.path.sep.join([covid_dataset_path, \"images\", row[\"filename\"]])\n","\n","    # if the input image file does not exist (there are some errors in\n","    # the COVID-19 metadeta file), ignore the row\n","    if not os.path.exists(imagePath):\n","        continue\n","\n","    # extract the filename from the image path and then construct the\n","    # path to the copied image file\n","    filename = row[\"filename\"].split(os.path.sep)[-1]\n","    outputPath = os.path.sep.join([f\"{dataset_path}/covid\", filename])\n","\n","    # copy the image\n","    shutil.copy2(imagePath, outputPath)"],"execution_count":11,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### Build normal xray dataset"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["def getDiretorio(tipo):\n","    retorno = \"\"\n","    if(tipo ==\"MaquinaLocal\"):\n","        retorno = r'D:\\Repos\\AprendendoPython\\MachineLearning\\Pos-GraduacaoCovid19'\n","    \n","    if(tipo ==\"GitHub\"):\n","        retorno = r'https://github.com/ieee8023/covid-chestxray-dataset/blob/master/'\n","    \n","    return retorno"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":"D:\\Repos\\AprendendoPython\\MachineLearning\\Pos-GraduacaoCovid19\nD:\\Repos\\AprendendoPython\\MachineLearning\\Pos-GraduacaoCovid19\\dataset\nD:\\Repos\\AprendendoPython\\MachineLearning\\Pos-GraduacaoCovid19\\Imagens_notebook\nD:\\Repos\\AprendendoPython\\MachineLearning\\Pos-GraduacaoCovid19\\dataset\\pneumonia\\normal\nD:\\Repos\\AprendendoPython\\MachineLearning\\Pos-GraduacaoCovid19\\dataset\\pneumonia\\PNEUMONIA\n"}],"source":["diretorio_raiz = getDiretorio(\"MaquinaLocal\")\n","diretorio_dataset =\"{0}\\{1}\".format(diretorio_raiz,'dataset')\n","diretorio_imagens_notebook =\"{0}\\{1}\".format(diretorio_raiz,'Imagens_notebook')\n","diretorio_pneumonia_normal =\"{0}\\{1}\\{2}\".format(diretorio_dataset,'pneumonia','normal')\n","diretorio_pneumonia_pneumonia =\"{0}\\{1}\\{2}\".format(diretorio_dataset,'pneumonia','PNEUMONIA')\n","# print(diretorio_kaggle_pneumonia)\n","print(diretorio_raiz)\n","print(diretorio_dataset)\n","print(diretorio_imagens_notebook)\n","print(diretorio_pneumonia_normal)\n","print(diretorio_pneumonia_pneumonia)"]},{"metadata":{"trusted":true},"cell_type":"code","source":["pneumonia_dataset_path ='../input/chest-xray-pneumonia/chest_xray'"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["\n","imagePaths = list(paths.list_images(diretorio_pneumonia_normal))\n","\n","# randomly sample the image paths\n","\n","# loop over the image paths\n","for (i, imagePath) in enumerate(imagePaths):\n","    # extract the filename from the image path and then construct the\n","    # path to the copied image file\n","    filename = imagePath.split(os.path.sep)[-1]\n","    outputPath = os.path.sep.join([f\"{dataset_path}/normal\", filename])\n","\n","    # copy the image\n","    shutil.copy2(imagePath, outputPath)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["samples = 130"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["basePath = os.path.sep.join([pneumonia_dataset_path, \"train\", \"PNEUMONIA\"])\n","imagePaths = list(paths.list_images(basePath))\n","\n","# randomly sample the image paths\n","random.seed(42)\n","random.shuffle(imagePaths)\n","imagePaths = imagePaths[:samples]\n","\n","# loop over the image paths\n","for (i, imagePath) in enumerate(imagePaths):\n","    # extract the filename from the image path and then construct the\n","    # path to the copied image file\n","    filename = imagePath.split(os.path.sep)[-1]\n","    outputPath = os.path.sep.join([f\"{dataset_path}/pneumonia\", filename])\n","\n","    # copy the image\n","    shutil.copy2(imagePath, outputPath)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## Plot x-rays"]},{"metadata":{"trusted":true},"cell_type":"code","source":["len(os.listdir('../working/dataset/normal'))"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["len(os.listdir('../working/dataset/pneumonia/'))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["Helper function to plot the images in a grid"]},{"metadata":{"trusted":true},"cell_type":"code","source":["def ceildiv(a, b):\n","    return -(-a // b)\n","\n","def plots_from_files(imspaths, figsize=(10,5), rows=1, titles=None, maintitle=None):\n","    \"\"\"Plot the images in a grid\"\"\"\n","    f = plt.figure(figsize=figsize)\n","    if maintitle is not None: plt.suptitle(maintitle, fontsize=10)\n","    for i in range(len(imspaths)):\n","        sp = f.add_subplot(rows, ceildiv(len(imspaths), rows), i+1)\n","        sp.axis('Off')\n","        if titles is not None: sp.set_title(titles[i], fontsize=16)\n","        img = plt.imread(imspaths[i])\n","        plt.imshow(img, cmap = 'gray')"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["normal_images = list(paths.list_images(f\"{dataset_path}/normal\"))\n","covid_images = list(paths.list_images(f\"{dataset_path}/covid\"))"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["plots_from_files(normal_images, rows=5, maintitle=\"Normal X-ray images\")"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["plots_from_files(covid_images, rows=5, maintitle=\"Covid-19 X-ray images\")"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## Data preprocessing"]},{"metadata":{"trusted":true},"cell_type":"code","source":["class_to_label_map = {'pneumonia' : 2, 'covid' : 1, 'normal' : 0}"],"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset_path =\"\""]},{"metadata":{"trusted":true},"cell_type":"code","source":["# grab the list of images in our dataset directory, then initialize\n","# the list of data (i.e., images) and class images\n","print(\"[INFO] loading images...\")\n","imagePaths = list(paths.list_images(dataset_path))\n","data = []\n","labels = []\n","# loop over the image paths\n","for imagePath in imagePaths:\n","    # extract the class label from the filename\n","    label = imagePath.split(os.path.sep)[-2]\n","    # load the image, swap color channels, and resize it to be a fixed\n","    # 224x224 pixels while ignoring aspect ratio\n","    image = cv2.imread(imagePath)\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    image = cv2.resize(image, (224, 224), interpolation = cv2.INTER_AREA)\n","    # update the data and labels lists, respectively\n","    data.append(image)\n","    labels.append(class_to_label_map[label])\n","# convert the data and labels to NumPy arrays while scaling the pixel\n","# intensities to the range [0, 1]\n","data = np.array(data) / 255.0\n","labels = np.array(labels)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# perform one-hot encoding on the labels\n","# perform one-hot encoding on the labels\n","#labels = to_categorical(labels)\n","# partition the data into training and testing splits using 80% of\n","# the data for training and the remaining 20% for testing\n","(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.15, stratify=labels, random_state=42)\n","# initialize the training data augmentation object\n","train_datagen = ImageDataGenerator(\n","                                   rotation_range=60,\n","                                   horizontal_flip = True ,\n","                                   vertical_flip = True ,\n","                                   fill_mode='nearest')\n","\n","val_datagen = ImageDataGenerator()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["trainYSparse = trainY\n","trainY = to_categorical(trainY)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## Model"]},{"metadata":{"trusted":true},"cell_type":"code","source":["def get_baseline_model(img_size):\n","  \n","    weight_decay = 1e-4\n","\n","    visible = Input(shape=(img_size, img_size, 3), dtype=tf.float32)\n","\n","    conv = Conv2D(32, (5, 5))(visible)\n","    conv_act = Activation('relu')(conv)\n","    conv_act_batch = BatchNormalization()(conv_act)\n","    conv_maxpool = MaxPooling2D()(conv_act_batch)\n","    conv_dropout = Dropout(0.1)(conv_maxpool)\n","\n","    conv = Conv2D(64, (3, 3))(conv_dropout)\n","    conv_act = Activation('relu')(conv)\n","    conv_act_batch = BatchNormalization()(conv_act)\n","    conv_maxpool = MaxPooling2D()(conv_act_batch)\n","    conv_dropout = Dropout(0.2)(conv_maxpool)\n","\n","    conv = Conv2D(128, (3, 3))(conv_dropout)\n","    conv_act = Activation('relu')(conv)\n","    conv_act_batch = BatchNormalization()(conv_act)\n","    conv_maxpool = MaxPooling2D()(conv_act_batch)\n","    conv_dropout = Dropout(0.3)(conv_maxpool)\n","\n","    conv = Conv2D(256, (3, 3))(conv_dropout)\n","    conv_act = Activation('relu')(conv)\n","    conv_act_batch = BatchNormalization()(conv_act)\n","    conv_maxpool = MaxPooling2D()(conv_act_batch)\n","    conv_dropout = Dropout(0.4)(conv_maxpool)\n","\n","    conv = Conv2D(512, (3, 3))(conv_dropout)\n","    conv_act = Activation('relu')(conv)\n","    conv_act_batch = BatchNormalization()(conv_act)\n","    conv_maxpool = MaxPooling2D()(conv_act_batch)\n","    conv_dropout = Dropout(0.5)(conv_maxpool)\n","    \n","    gap2d = GlobalAveragePooling2D()(conv_dropout)\n","    act = Activation('relu')(gap2d)\n","    batch = BatchNormalization()(act)\n","    dropout = Dropout(0.3)(batch)\n","\n","    fc1 = Dense(256)(dropout)\n","    act = Activation('relu')(fc1)\n","    batch = BatchNormalization()(act)\n","    dropout = Dropout(0.4)(batch)\n","\n","    # and a logistic layer\n","    predictions = Dense(3, activation='softmax')(dropout)\n","    \n","    # Create model.\n","    model = tf.keras.Model(visible, predictions, name='baseline')\n","\n","    return model\n","model = get_baseline_model(224)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["from math import floor\n","N_FOLDS = 8\n","EPOCHS = 8\n","INIT_LR = 3e-4\n","T_BS = 16\n","V_BS = 16\n","decay_rate = 0.95\n","decay_step = 1\n","\n","skf = StratifiedKFold(n_splits=N_FOLDS, random_state=1234,)\n","log_dir = \"./logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n","\n","callbacks = [ModelCheckpoint(filepath='best_vgg16_model.h5', monitor='val_loss',mode='min',verbose=1,save_best_only=True,save_weights_only=True),\n","             LearningRateScheduler(lambda epoch : INIT_LR * pow(decay_rate, floor(epoch / decay_step))), tensorboard_callback]"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["resnet34, _ = Classifiers.get('densenet121')\n","conv_base = resnet34(weights='imagenet',\n","              include_top=False,\n","              input_shape=(224, 224, 3))\n","\n","conv_base.trainable = False\n","\n","\n","gap2d = GlobalAveragePooling2D()(conv_base.output)\n","act = Activation('relu')(gap2d)\n","batch = BatchNormalization()(act)\n","dropout = Dropout(0.3)(batch)\n","\n","fc1 = Dense(256)(dropout)\n","act = Activation('relu')(fc1)\n","batch = BatchNormalization()(act)\n","dropout = Dropout(0.4)(batch)\n","predictions = Dense(3, activation='softmax')(dropout)\n","\n","model = Model(conv_base.input, predictions)\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=Adam(lr=INIT_LR),\n","              metrics=['acc', tf.keras.metrics.AUC()])"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### Training"]},{"metadata":{"trusted":true},"cell_type":"code","source":["submission_predictions = []\n","for epoch, skf_splits in zip(range(0,N_FOLDS),skf.split(trainX,trainYSparse)):\n","\n","    train_idx = skf_splits[0]\n","    val_idx = skf_splits[1]\n","    \n","    # Create Model\n","    resnet34, _ = Classifiers.get('densenet121')\n","    conv_base = resnet34(weights='imagenet',\n","                  include_top=False,\n","                  input_shape=(224, 224, 3))\n","\n","    conv_base.trainable = False\n","\n","\n","    gap2d = GlobalAveragePooling2D()(conv_base.output)\n","    act = Activation('relu')(gap2d)\n","    batch = BatchNormalization()(act)\n","    dropout = Dropout(0.3)(batch)\n","\n","    fc1 = Dense(256)(dropout)\n","    act = Activation('relu')(fc1)\n","    batch = BatchNormalization()(act)\n","    dropout = Dropout(0.4)(batch)\n","    predictions = Dense(3, activation='softmax')(dropout)\n","\n","    model = Model(conv_base.input, predictions)\n","    model.compile(loss='categorical_crossentropy',\n","                  optimizer=Adam(lr=INIT_LR),\n","                  metrics=['acc', tf.keras.metrics.AUC()])\n","    \n","    if epoch != 0:\n","        # Load Model Weights\n","        model.load_weights('best_vgg16_model.h5') \n","    \n","    history = model.fit(\n","                train_datagen.flow(trainX[train_idx], trainY[train_idx], batch_size=T_BS),\n","                steps_per_epoch=len(train_idx) // T_BS,\n","                epochs=EPOCHS,\n","                validation_data = val_datagen.flow(trainX[val_idx], trainY[val_idx], batch_size=V_BS),\n","                validation_steps = len(val_idx) // V_BS,\n","                callbacks=callbacks)\n","    \n","    if epoch >= 1:\n","        preds = model.predict(testX, batch_size=V_BS)\n","        submission_predictions.append(preds)\n","    \n","    plt.plot(history.history['loss'], label='train')\n","    plt.plot(history.history['val_loss'], label='valid')\n","    plt.title(\"model loss\")\n","    plt.ylabel(\"loss\")\n","    plt.xlabel(\"number of epochs\")\n","    plt.legend([\"train\", \"valid\"], loc=\"upper left\")\n","    plt.savefig('loss_performance'+'_'+str(epoch)+'.png')\n","    plt.clf()\n","    plt.plot(history.history['acc'], label='train')\n","    plt.plot(history.history['val_acc'], label='valid')\n","    plt.title(\"model acc\")\n","    plt.ylabel(\"accuracy\")\n","    plt.xlabel(\"number of epochs\")\n","    plt.legend([\"train\", \"valid\"], loc=\"upper left\")\n","    plt.savefig('acc_performance'+'_'+str(epoch)+'.png')\n","    \n","    del history\n","    del model\n","    gc.collect()\n","    "],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## Grad-CAM"]},{"metadata":{"trusted":true},"cell_type":"code","source":["class GradCAM:\n","\tdef __init__(self, model, classIdx, layerName=None):\n","\t\t# store the model, the class index used to measure the class\n","\t\t# activation map, and the layer to be used when visualizing\n","\t\t# the class activation map\n","\t\tself.model = model\n","\t\tself.classIdx = classIdx\n","\t\tself.layerName = layerName\n","\n","\t\t# if the layer name is None, attempt to automatically find\n","\t\t# the target output layer\n","\t\tif self.layerName is None:\n","\t\t\tself.layerName = self.find_target_layer()\n","\n","\tdef find_target_layer(self):\n","\t\t# attempt to find the final convolutional layer in the network\n","\t\t# by looping over the layers of the network in reverse order\n","\t\tfor layer in reversed(self.model.layers):\n","\t\t\t# check to see if the layer has a 4D output\n","\t\t\tif len(layer.output_shape) == 4:\n","\t\t\t\treturn layer.name\n","\n","\t\t# otherwise, we could not find a 4D layer so the GradCAM\n","\t\t# algorithm cannot be applied\n","\t\traise ValueError(\"Could not find 4D layer. Cannot apply GradCAM.\")\n","\n","\tdef compute_heatmap(self, image, eps=1e-8):\n","\t\t# construct our gradient model by supplying (1) the inputs\n","\t\t# to our pre-trained model, (2) the output of the (presumably)\n","\t\t# final 4D layer in the network, and (3) the output of the\n","\t\t# softmax activations from the model\n","\t\tgradModel = Model(\n","\t\t\tinputs=[self.model.inputs],\n","\t\t\toutputs=[self.model.get_layer(self.layerName).output, \n","                     \n","\t\t\t\tself.model.output])\n","\n","\t\t# record operations for automatic differentiation\n","\t\twith tf.GradientTape() as tape:\n","\t\t\t# cast the image tensor to a float-32 data type, pass the\n","\t\t\t# image through the gradient model, and grab the loss\n","\t\t\t# associated with the specific class index\n","\t\t\tinputs = tf.cast(image, tf.float32)\n","\t\t\t(convOutputs, predictions) = gradModel(inputs)\n","\t\t\tloss = predictions[:, self.classIdx]\n","\n","\t\t# use automatic differentiation to compute the gradients\n","\t\tgrads = tape.gradient(loss, convOutputs)\n","\n","\t\t# compute the guided gradients\n","\t\tcastConvOutputs = tf.cast(convOutputs > 0, \"float32\")\n","\t\tcastGrads = tf.cast(grads > 0, \"float32\")\n","\t\tguidedGrads = castConvOutputs * castGrads * grads\n","\n","\t\t# the convolution and guided gradients have a batch dimension\n","\t\t# (which we don't need) so let's grab the volume itself and\n","\t\t# discard the batch\n","\t\tconvOutputs = convOutputs[0]\n","\t\tguidedGrads = guidedGrads[0]\n","\n","\t\t# compute the average of the gradient values, and using them\n","\t\t# as weights, compute the ponderation of the filters with\n","\t\t# respect to the weights\n","\t\tweights = tf.reduce_mean(guidedGrads, axis=(0, 1))\n","\t\tcam = tf.reduce_sum(tf.multiply(weights, convOutputs), axis=-1)\n","\n","\t\t# grab the spatial dimensions of the input image and resize\n","\t\t# the output class activation map to match the input image\n","\t\t# dimensions\n","\t\t(w, h) = (image.shape[2], image.shape[1])\n","\t\theatmap = cv2.resize(cam.numpy(), (w, h))\n","\n","\t\t# normalize the heatmap such that all values lie in the range\n","\t\t# [0, 1], scale the resulting values to the range [0, 255],\n","\t\t# and then convert to an unsigned 8-bit integer\n","\t\tnumer = heatmap - np.min(heatmap)\n","\t\tdenom = (heatmap.max() - heatmap.min()) + eps\n","\t\theatmap = numer / denom\n","\t\theatmap = (heatmap * 255).astype(\"uint8\")\n","\n","\t\t# return the resulting heatmap to the calling function\n","\t\treturn heatmap\n","\n","\tdef overlay_heatmap(self, heatmap, image, alpha=0.5,\n","\t\tcolormap=cv2.COLORMAP_JET):\n","\t\t# apply the supplied color map to the heatmap and then\n","\t\t# overlay the heatmap on the input image\n","\t\theatmap = cv2.applyColorMap(heatmap, colormap)\n","\t\toutput = cv2.addWeighted(image, alpha, heatmap, 1 - alpha, 0)\n","\n","\t\t# return a 2-tuple of the color mapped heatmap and the output,\n","\t\t# overlaid image\n","\t\treturn (heatmap, output)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["model.load_weights('../working/best_vgg16_model.h5')"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["np.where(testY == 0)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["covid1 = testX[50]\n","covid2 = testX[4]\n","covid3 = testX[35]\n","covid_list = [covid1, covid2, covid3]\n","pneumonia1 = testX[2]\n","pneumonia2 = testX[43]\n","pneumonia3 = testX[52]\n","pneumonia_list = [pneumonia1, pneumonia2, pneumonia3]"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["image = testX[7]\n","preds = model.predict(image[np.newaxis,...])\n","preds"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["\n","preds = model.predict(image[np.newaxis,...])\n","i = np.argmax(preds[0])\n","\n","# decode the ImageNet predictions to obtain the human-readable label\n","\n","# # initialize our gradient class activation map and build the heatmap\n","cam = GradCAM(model, i)\n","heatmap = cam.compute_heatmap(image[np.newaxis,...])\n","\n","img_copy = np.copy(image)\n","img_copy -= img_copy.min((0,1))\n","img_copy = (255*img_copy).astype(np.uint8)\n","# resize the resulting heatmap to the original input image dimensions\n","# and then overlay heatmap on top of the image\n","heatmap = cv2.resize(heatmap, (image.shape[1], image.shape[0]))\n","(heatmap, output) = cam.overlay_heatmap(heatmap, img_copy, alpha=0.5)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["plt.imshow(output, cmap = 'gray')"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["def plot_map(img_list):\n","    fig, axes = plt.subplots(len(img_list), 2, figsize=(15, 15))\n","    fig.suptitle('Pneumonia Grad-CAM\\n',fontsize=20)\n","    \n","    for i, img in enumerate(img_list):\n","        preds = model.predict(img[np.newaxis,...])\n","        axes[i,0].imshow(img, cmap = 'bone')\n","        axes[i,0].set_xticks([])\n","        axes[i,0].set_yticks([])\n","      #  axes[i,0].set_title(f'{class_label[np.argmax(preds[:, 1:]) + 1]} / {class_label[np.argmax(label[:, 1:]) + 1]} / {np.max(preds[:, 1:]):.4f}')\n","        heatmap = cam.compute_heatmap(img[np.newaxis,...])\n","        img_copy = np.copy(img)\n","        img_copy -= img_copy.min((0,1))\n","        img_copy = (255*img_copy).astype(np.uint8)\n","        # resize the resulting heatmap to the original input image dimensions\n","        # and then overlay heatmap on top of the image\n","        heatmap = cv2.resize(heatmap, (img_copy.shape[1], img_copy.shape[0]))\n","        (heatmap, output) = cam.overlay_heatmap(heatmap, img_copy, alpha=0.5)\n","        axes[i,1].imshow(output)\n","        axes[i,1].set_xticks([])\n","        axes[i,1].set_yticks([])\n","        #axes[i,1].set_title(\"heatmap showing hemorrhage location\")\n","    plt.subplots_adjust(wspace=1, hspace=0.2)\n","    plt.savefig('CovidGradCAM.png')"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["plot_map(covid_list)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["plot_map(pneumonia_list)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### Evaluation"]},{"metadata":{"trusted":true},"cell_type":"code","source":["predY = np.average(submission_predictions, axis = 0, weights = [2**i for i in range(len(submission_predictions))])"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["roc_auc_score(testY, predY, multi_class='ovo')"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["roc_auc_score(testY, predY, multi_class='ovr')"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["class_to_label_map = {2 : 'pneumonia', 1 : 'covid', 0 : 'normal'}"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["import seaborn as sns\n","def plot_multiclass_roc(y_test, y_score, n_classes, figsize=(17, 6)):\n","\n","    # structures\n","    fpr = dict()\n","    tpr = dict()\n","    roc_auc = dict()\n","\n","    # calculate dummies once\n","    y_test_dummies = pd.get_dummies(y_test, drop_first=False).values\n","    for i in range(n_classes):\n","        fpr[i], tpr[i], _ = roc_curve(y_test_dummies[:, i], y_score[:, i])\n","        roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","    # roc for each class\n","    fig, ax = plt.subplots(figsize=figsize)\n","    ax.plot([0, 1], [0, 1], 'k--')\n","    ax.set_xlim([0.0, 1.0])\n","    ax.set_ylim([0.0, 1.05])\n","    ax.set_xlabel('False Positive Rate')\n","    ax.set_ylabel('True Positive Rate')\n","    ax.set_title('Receiver operating characteristic example')\n","    for i in range(n_classes):\n","        ax.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f) for %s' % (roc_auc[i], class_to_label_map[i]))\n","    ax.legend(loc=\"best\")\n","    ax.grid(alpha=.4)\n","    sns.despine()\n","    plt.show()\n","\n","plot_multiclass_roc(testY, predY, n_classes=3, figsize=(16, 10))"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["cm_mat = confusion_matrix(testY, np.argmax(predY, axis = -1))"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["import numpy as np\n","\n","def plot_confusion_matrix(cm,\n","                          target_names,\n","                          title='Confusion matrix',\n","                          cmap=None,\n","                          normalize=True):\n","    \"\"\"\n","    given a sklearn confusion matrix (cm), make a nice plot\n","\n","    Arguments\n","    ---------\n","    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n","\n","    target_names: given classification classes such as [0, 1, 2]\n","                  the class names, for example: ['high', 'medium', 'low']\n","\n","    title:        the text to display at the top of the matrix\n","\n","    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n","                  see http://matplotlib.org/examples/color/colormaps_reference.html\n","                  plt.get_cmap('jet') or plt.cm.Blues\n","\n","    normalize:    If False, plot the raw numbers\n","                  If True, plot the proportions\n","\n","    Usage\n","    -----\n","    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n","                                                              # sklearn.metrics.confusion_matrix\n","                          normalize    = True,                # show proportions\n","                          target_names = y_labels_vals,       # list of names of the classes\n","                          title        = best_estimator_name) # title of graph\n","\n","    Citiation\n","    ---------\n","    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n","\n","    \"\"\"\n","    import matplotlib.pyplot as plt\n","    import numpy as np\n","    import itertools\n","\n","    accuracy = np.trace(cm) / float(np.sum(cm))\n","    misclass = 1 - accuracy\n","\n","    if cmap is None:\n","        cmap = plt.get_cmap('Blues')\n","\n","    plt.figure(figsize=(8, 6))\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title, fontsize = 'xx-large')\n","\n","    if target_names is not None:\n","        tick_marks = np.arange(len(target_names))\n","        plt.xticks(tick_marks, target_names, rotation=45)\n","        plt.yticks(tick_marks, target_names)\n","\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","\n","\n","    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        if normalize:\n","            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n","                     horizontalalignment=\"center\",\n","                     color=\"white\" if cm[i, j] > thresh else \"black\")\n","        else:\n","            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n","                     horizontalalignment=\"center\",\n","                     color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n","    plt.show()\n","    \n","plot_confusion_matrix(cm_mat, \n","                      normalize = False,\n","                      target_names = ['normal', 'covid', 'pneumonia'],\n","                      title        = \"Confusion Matrix\")"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["print(classification_report(testY, np.argmax(predY, axis = -1), target_names = ['normal', 'covid', 'pneumonia']))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["#### Confusion matrix"]},{"metadata":{"trusted":true},"cell_type":"code","source":["# compute the confusion matrix and and use it to derive the raw\n","# accuracy, sensitivity, and specificity\n","cm = confusion_matrix(testY, np.argmax(predY, axis = -1))\n","total = sum(sum(cm))\n","acc = (cm[0, 0] + cm[1, 1]) / total\n","sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n","specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n","# show the confusion matrix, accuracy, sensitivity, and specificity\n","print(cm)\n","print(\"acc: {:.4f}\".format(acc))\n","print(\"sensitivity: {:.4f}\".format(sensitivity))\n","print(\"specificity: {:.4f}\".format(specificity))"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["!rm -rf dataset\n","!rm -rf logs"],"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3.7.7 64-bit ('Deep Learning': conda)","name":"python37764bitdeeplearningconda70b0a9c2c78b49cfaeeb6e88dd7dfba8"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.7.7-final","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}